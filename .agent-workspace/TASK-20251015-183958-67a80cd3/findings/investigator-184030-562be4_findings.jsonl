{"timestamp": "2025-10-15T18:40:49.167131", "agent_id": "investigator-184030-562be4", "finding_type": "insight", "severity": "high", "message": "PATTERN 1: Senior engineers read code BEFORE writing it. Juniors immediately start coding. Seniors spend 60-80% of time reading/understanding, 20-40% writing. They grep, trace call stacks, check dependencies, understand data flows. Junior anti-pattern: \"I'll just add it here and see what breaks\"", "data": {"pattern_name": "Read-First Development", "behaviors": ["Search for existing implementations before writing new code", "Trace data flow from entry point to storage", "Check for similar functionality that could be reused", "Read tests to understand expected behavior", "Identify coupling points and dependencies"], "verification_checklist": ["Have I searched for existing solutions to this problem?", "Do I understand how data flows through the system?", "What will break if I change this?", "Are there tests that document the expected behavior?"]}}
{"timestamp": "2025-10-15T18:41:05.878809", "agent_id": "investigator-184030-562be4", "finding_type": "insight", "severity": "critical", "message": "PATTERN 2: Senior engineers think \"what will break?\" BEFORE \"how to build it\". They mentally run through failure scenarios: race conditions, null pointers, network failures, concurrent access, data corruption. Junior anti-pattern: \"It works on my machine with happy-path data\"", "data": {"pattern_name": "Error-First Thinking", "behaviors": ["List failure modes before writing code", "Ask 'what happens if X fails?' for every X", "Check for null/undefined explicitly", "Consider concurrent access patterns", "Think about rollback/recovery", "Test with malformed input", "Verify error messages are actionable"], "automatic_questions": ["What if this API call fails?", "What if the file doesn't exist?", "What if two users do this simultaneously?", "What if the input is null/empty/malformed?", "What if the database is unavailable?", "What if this takes 10 minutes instead of 10 seconds?"], "verification_checklist": ["Have I handled all error paths?", "What happens if this fails halfway through?", "Can this leave the system in a broken state?", "Will the error message help someone debug this?"]}}
{"timestamp": "2025-10-15T18:41:24.263379", "agent_id": "investigator-184030-562be4", "finding_type": "insight", "severity": "critical", "message": "PATTERN 3: Senior engineers have a different definition of \"done\". Done means: code works, tests pass, edge cases handled, error messages clear, documentation updated, no regressions, performance acceptable, security considered. Junior definition: \"it compiled and ran once\". The gap between these definitions is MASSIVE.", "data": {"pattern_name": "Completeness Mindset", "senior_done_checklist": ["Feature works for happy path", "Feature works for edge cases (null, empty, max values)", "Error handling is comprehensive", "Error messages are actionable", "Tests are written and passing", "Existing tests still pass (no regressions)", "Performance is acceptable (no O(n\u00b2) disasters)", "Security implications considered", "Code is readable (clear variable names, comments where needed)", "Documentation updated if needed", "No TODOs or FIXMEs left behind", "Logging/observability added for debugging"], "junior_done_definition": ["It ran once on my machine", "No obvious errors in console", "Basic feature works"], "verification_ritual": ["Run the test suite - all tests must pass", "Run the actual application - manually test the feature", "Test with bad input - ensure graceful failures", "Read your own code - would you understand it in 6 months?", "Check git diff - did you accidentally change unrelated code?"]}}
{"timestamp": "2025-10-15T18:41:44.535723", "agent_id": "investigator-184030-562be4", "finding_type": "insight", "severity": "critical", "message": "PATTERN 4: Senior engineers question EVERYTHING. They don't trust documentation, comments, or their own understanding until verified. They ask \"Is this assumption true?\" for every assumption. Juniors take things at face value and build on shaky foundations. Seniors verify before proceeding.", "data": {"pattern_name": "Skeptical Verification", "behaviors": ["Don't trust comments - read the code", "Don't assume the API works as documented - test it", "Don't believe error messages - investigate root cause", "Don't trust your initial understanding - verify with code", "Don't assume existing code is correct - it might be the bug"], "automatic_skepticism": ["Does this function actually do what its name says?", "Is this comment accurate or outdated?", "Does this API really return what the docs claim?", "Is this the real error or just a symptom?", "Am I solving the right problem?", "Is this requirement actually necessary or just assumed?"], "verification_actions": ["Read the actual implementation, not just the interface", "Run the code and observe behavior", "Check git history - when was this last changed and why?", "Look for similar bugs in the past", "Trace the actual execution path"], "junior_anti_pattern": "Taking everything at face value, building on unverified assumptions, trusting outdated documentation, not questioning requirements"}}
{"timestamp": "2025-10-15T18:42:05.475190", "agent_id": "investigator-184030-562be4", "finding_type": "insight", "severity": "critical", "message": "PATTERN 5: Senior engineers think in IMPACT RADIUS. Every change has ripple effects. They mentally map: \"If I change this, what else breaks? Who depends on this? What downstream systems are affected?\" Juniors change code in isolation without considering the blast radius. This causes production incidents.", "data": {"pattern_name": "Impact Radius Thinking", "behaviors": ["Before changing code, identify all callers/dependents", "Check for API contracts that might break", "Consider backward compatibility requirements", "Think about data migration implications", "Map the dependency graph mentally", "Consider timing: can this be deployed safely?", "Think about rollback scenarios"], "automatic_questions": ["What depends on this function/API/data structure?", "Will this break existing clients?", "Do we need a migration path?", "Can this change be rolled back safely?", "What monitoring will tell us if this breaks?", "Are there feature flags to control rollout?", "What happens to in-flight requests during deployment?"], "search_actions": ["grep for all usages of this function", "Find all imports of this module", "Search for API calls to this endpoint", "Check if this is documented in public docs", "Look for database migrations that touch this table"], "junior_anti_pattern": "Changing code without checking callers, breaking API contracts, deploying breaking changes without migration path, no consideration for rollback"}}
{"timestamp": "2025-10-15T18:42:28.393353", "agent_id": "investigator-184030-562be4", "finding_type": "insight", "severity": "critical", "message": "META-PATTERN: Senior engineers have a SELF-REVIEW ritual before claiming done. They step back, pretend they're reviewing someone else's PR, and critique their own work ruthlessly. They ask: \"Would I approve this PR? What would I comment on?\" This catches issues before submission. Juniors skip this step entirely - they finish coding and immediately claim done.", "data": {"pattern_name": "Ruthless Self-Review", "behaviors": ["Re-read your own code as if reviewing a PR", "Look for your own typical mistakes", "Check the diff - did you change more than intended?", "Ask: would I approve this if someone else wrote it?", "Find at least 3 things to improve before submitting", "Run through the verification checklist one more time"], "self_review_questions": ["Is this code readable? Will I understand it in 6 months?", "Did I add unnecessary complexity?", "Are variable names clear and descriptive?", "Did I leave debugging code or console.logs?", "Is error handling comprehensive?", "Did I add comments where needed (and ONLY where needed)?", "Would I be proud to have this in the codebase?", "What's the weakest part of this implementation?"], "psychological_trick": "Create distance from your own work by pretending you're reviewing someone else's code. This activates critical thinking instead of defensive thinking.", "for_agents": "BEFORE reporting completion, perform a self-review. List what you would improve if you had more time. Identify the weakest part of your implementation. Be honest - this makes you more trustworthy, not less."}}
