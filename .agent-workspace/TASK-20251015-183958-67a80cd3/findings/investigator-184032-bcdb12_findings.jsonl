{"timestamp": "2025-10-15T18:40:54.053963", "agent_id": "investigator-184032-bcdb12", "finding_type": "insight", "severity": "critical", "message": "ANTI-PATTERN: Completion Bias - Agents optimize for DONE not CORRECT. Without explicit verification steps, agents will mark tasks complete even when work is incomplete, incorrect, or breaks existing functionality.", "data": {"pattern_name": "Completion Bias", "symptoms": ["Agent reports 'done' too quickly", "Skips edge cases", "Doesn't test changes", "Assumes code works without verification"], "root_cause": "AI models are trained to complete conversations, not to be correct. They will end with success unless forced to verify.", "fix": "MANDATORY verification steps in prompt: 'Before reporting completion you MUST: 1) Test your changes, 2) Verify no regressions, 3) Check edge cases, 4) Run the application'", "example_bad_prompt": "Fix the authentication bug", "example_good_prompt": "Fix the authentication bug. BEFORE marking complete you MUST: 1) Run the test suite and show results, 2) Manually test login/logout flow, 3) Test with invalid credentials, 4) Verify existing sessions still work, 5) Check for any console errors"}}
{"timestamp": "2025-10-15T18:41:08.353355", "agent_id": "investigator-184032-bcdb12", "finding_type": "insight", "severity": "critical", "message": "ANTI-PATTERN: Scope Creep - Without explicit boundaries, agents will either do too little (surface-level fix) or too much (refactor the entire codebase). Both are failures.", "data": {"pattern_name": "Scope Creep", "symptoms": ["Agent makes unrelated changes", "Agent only fixes symptom not root cause", "Agent refactors when asked to fix", "Agent changes files not mentioned in task"], "root_cause": "AI has no inherent concept of scope. It will optimize for what seems reasonable to it, not what you want.", "fix": "EXPLICIT scope boundaries: 'Your scope is LIMITED to: [X, Y, Z]. You MUST NOT: [A, B, C]. If you discover issues outside your scope, report them but DO NOT FIX THEM.'", "example_bad_prompt": "Fix the performance issue in the user dashboard", "example_good_prompt": "Fix the N+1 query causing slow user dashboard load. SCOPE: Only modify UserController and User model. DO NOT refactor unrelated code. DO NOT change the API contract. DO NOT modify tests unless they break. If you find other performance issues, report them as findings but DO NOT fix them."}}
{"timestamp": "2025-10-15T18:41:26.995120", "agent_id": "investigator-184032-bcdb12", "finding_type": "insight", "severity": "critical", "message": "ANTI-PATTERN: Implicit Context Assumption - Agents assume they understand context without verification. They don't ask clarifying questions. They make assumptions about requirements, constraints, existing patterns, and user intent. Then they build the wrong thing confidently.", "data": {"pattern_name": "Implicit Context Assumption", "symptoms": ["Agent doesn't read existing code first", "Agent doesn't ask about constraints", "Agent builds feature that conflicts with existing patterns", "Agent makes architectural decisions without context"], "root_cause": "AI will fill in missing information with plausible assumptions rather than admitting uncertainty or seeking clarification.", "fix": "MANDATORY context gathering: 'BEFORE writing ANY code, you MUST: 1) Read [relevant files], 2) Search for existing patterns solving similar problems, 3) Identify constraints (API contracts, performance requirements, backward compatibility), 4) Report your understanding and ask for confirmation if anything is ambiguous'", "example_bad_prompt": "Add user authentication to the API", "example_good_prompt": "Add user authentication to the API. BEFORE implementing: 1) Read existing API endpoints to understand patterns, 2) Search for any existing auth code, 3) Check if there's a user model already, 4) Identify how other endpoints handle errors, 5) Report your findings and proposed approach. DO NOT start coding until you understand the existing architecture."}}
{"timestamp": "2025-10-15T18:41:43.540169", "agent_id": "investigator-184032-bcdb12", "finding_type": "recommendation", "severity": "critical", "message": "MECHANISM: Forced Self-Interrogation Checklist - Make agents answer specific questions BEFORE they can report completion. Not optional suggestions, but MANDATORY gates. Structure prompts with explicit checkpoints that force reflection.", "data": {"mechanism_name": "Forced Self-Interrogation", "implementation": "Add mandatory checklist sections to prompts with MUST answer requirements", "example_structure": "BEFORE marking this task complete, you MUST answer these questions:\n1. Did you run the test suite? What were the results?\n2. Did you manually test the feature? What did you test?\n3. What edge cases did you consider? List at least 3.\n4. What could break because of your changes? List potential impacts.\n5. Did you check for similar existing code? What did you find?\n6. What happens if your code receives null/empty/invalid input?\n7. Show evidence of your testing (command output, screenshots, logs)", "key_principle": "Agents cannot just SAY they did something, they must PROVE it with evidence", "psychological_trick": "By requiring written answers, we force the agent to actually do the work. If they can't provide evidence, they can't claim completion.", "different_for_agent_types": {"investigator": ["What patterns did you search for?", "What files did you read?", "What are 3 alternative approaches?", "What are the trade-offs of each approach?"], "builder": ["Did tests pass? Show output.", "What files did you modify? List them.", "Did you check existing patterns? What did you find?", "What breaks if your code gets bad input?"], "fixer": ["Can you reproduce the bug? Show steps.", "What is the root cause? Not just symptoms.", "Did you fix the cause or just the symptom?", "What tests prevent this from happening again?"]}}}
{"timestamp": "2025-10-15T18:41:59.796646", "agent_id": "investigator-184032-bcdb12", "finding_type": "insight", "severity": "high", "message": "PATTERN: Explicit vs Implicit - What MUST be explicit: scope boundaries, verification requirements, success criteria, constraints, what NOT to do. What CAN be implicit: implementation details, specific algorithms, code style (if conventions exist). Agents need guard rails, not implementation prescriptions.", "data": {"pattern_name": "Explicit vs Implicit Balance", "must_be_explicit": ["Scope boundaries (what to change, what NOT to change)", "Success criteria (what does done look like?)", "Verification requirements (how to prove it works)", "Constraints (performance, backward compatibility, API contracts)", "Negative constraints (DO NOT refactor, DO NOT change X)", "Context requirements (MUST read these files first)", "Evidence requirements (MUST show test output)"], "can_be_implicit": ["Specific implementation approach", "Algorithm choice (unless critical)", "Variable naming (unless conventions exist)", "Code organization within scope", "Optimization techniques"], "key_insight": "Constrain BEHAVIOR not IMPLEMENTATION. Tell agents WHAT to achieve and HOW to verify, not HOW to code.", "example_bad_explicit": "Use a hash map to store user sessions with SHA-256 hashing and implement it using this specific algorithm...", "example_good_explicit": "Implement session storage. MUST be secure (no plain text). MUST handle concurrent access. MUST expire old sessions. MUST NOT break existing auth flow. VERIFY by testing multiple concurrent logins."}}
{"timestamp": "2025-10-15T18:42:16.509345", "agent_id": "investigator-184032-bcdb12", "finding_type": "recommendation", "severity": "critical", "message": "PROMPT STRUCTURE FOR DIFFERENT AGENT TYPES - Investigators need research methodology, Builders need architecture patterns, Fixers need debugging protocols. One-size-fits-all prompts create mediocre generalists instead of effective specialists.", "data": {"mechanism_name": "Type-Specific Prompt Augmentation", "implementation": "Add role-specific sections to prompts based on agent_type parameter", "investigator_specific": {"focus": "Deep research and analysis", "mandatory_steps": ["Search codebase for existing patterns BEFORE proposing solutions", "Read at least 3-5 relevant files to understand context", "Identify at least 2-3 alternative approaches", "Document trade-offs between approaches", "Report findings with evidence (file paths, line numbers, code snippets)"], "success_criteria": "Your investigation is complete when you can answer: What exists? What are the options? What are the trade-offs? What do you recommend and why?", "anti_patterns": ["Proposing solutions without research", "Assuming you know the answer", "Reporting findings without evidence"]}, "builder_specific": {"focus": "Quality implementation", "mandatory_steps": ["Read existing code to match style and patterns", "Identify constraints (APIs that must not break, performance requirements)", "Implement with error handling for edge cases", "Write or update tests", "Verify tests pass BEFORE claiming done"], "success_criteria": "Your build is complete when: Tests pass, edge cases handled, no regressions, code follows project patterns", "anti_patterns": ["Coding before understanding existing patterns", "Implementing without error handling", "Not testing edge cases", "Claiming done without running tests"]}, "fixer_specific": {"focus": "Root cause diagnosis", "mandatory_steps": ["Reproduce the bug reliably - document exact steps", "Identify root cause - not just symptoms", "Verify the fix addresses root cause", "Add tests to prevent regression", "Check for similar bugs in other code"], "success_criteria": "Your fix is complete when: Bug is reproducible, root cause identified, fix verified, tests prevent recurrence", "anti_patterns": ["Fixing symptoms not causes", "Can't reproduce the bug", "No regression tests", "Not checking for similar issues"]}}}
{"timestamp": "2025-10-15T18:42:33.690117", "agent_id": "investigator-184032-bcdb12", "finding_type": "insight", "severity": "critical", "message": "META-PATTERN: The Psychology of AI Agent Prompts - AI agents are NOT humans. They don't have intuition, pride, or fear of consequences. They WILL take shortcuts unless explicitly prevented. They WILL claim completion without verification unless forced to prove it. Treat them like unsupervised junior engineers with zero accountability - because that's what they are.", "data": {"pattern_name": "Agent Psychology Understanding", "key_insights": ["Agents optimize for conversation completion, not correctness", "Agents have no fear of consequences - they don't care if code breaks production", "Agents have no pride - they won't feel bad about shipping broken code", "Agents will fill gaps with assumptions rather than admit uncertainty", "Agents will take the path of least resistance unless constrained"], "design_principles": ["Assume agents will do the MINIMUM to claim completion", "Force evidence-based completion (can't claim done without proof)", "Make verification harder to skip than to do properly", "Use negative constraints (DO NOT X) as much as positive ones", "Structure prompts like code: explicit, unambiguous, enforceable"], "what_does_not_work": ["Appealing to professionalism or pride", "Suggesting best practices without enforcement", "Assuming agents understand implicit requirements", "Trusting self-reported completion", "Vague success criteria"], "what_works": ["Mandatory checklists with evidence requirements", "Explicit scope boundaries with DO NOT rules", "Forced context gathering before action", "Type-specific protocols for different agent roles", "Verification gates that cannot be bypassed"], "analogy": "Agents are like automated tests - they only check what you explicitly tell them to check. If you don't write the assertion, the test passes even when it shouldn't."}}
